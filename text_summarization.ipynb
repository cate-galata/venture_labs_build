{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Session Text Summarization\n",
    "This is the hands-on session accompanying the workshop on LangChain fundamentals. This is inspired by the more extensive LangChain Cookbook Part 1.\n",
    "\n",
    "Copyright (c) 2023 Michael Neumayr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set up the Colab in your drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load this Colab from Github\n",
    "- Run the first cell to install all required packages (this takes a moment)\n",
    "- During installation jump to section \"Set OpenAI API Key\" and put the key we provide you instead of \"PUT_YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages; this may take some minutes; ignore dependency warnings it should work anyway\n",
    "%pip install openai\n",
    "%pip install langchain\n",
    "%pip install pypdf\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the workshop github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/michaelnoi/venture_labs_build.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd venture_labs_build && git checkout only_static_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY', 'PUT_YOUR_KEY_HERE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optional: Connect to your Google Drive storage to upload your own documents later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to your google drive storage to use your own documents\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Summarize short pdf document at once (\"stuff\" method)\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <b>Context Size</b>\n",
    "  <p>Most basic models have a context size (max. number of input tokens) around 2k (GPT3) - 32k (GPT4), but the price for larger context sizes goes up per 1000 tokens. For our GPT 3.5 Turbo model, the context size is 4k tokens, so our short prompt + the document without the reference pages should work inputting it at once. Let's try!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# load short business model canvas pdf again\n",
    "pdf_path = \"static/business_Model_Canvas.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the business model canvas wikipedia again as pdf document. Let's first check out how many tokens the document has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of tokens in each page\n",
    "overall_tokens = 0\n",
    "for page in documents:\n",
    "    n_tokens = llm.get_num_tokens(page.page_content)\n",
    "    print(f\"Number of tokens in page {page.metadata['page']}: {n_tokens}\")\n",
    "    overall_tokens += n_tokens\n",
    "print(f\"Overall number of tokens: {overall_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop last two pages (references) and add the whole article to a prompt for summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <p>Try to get a summary for 5 year olds and the summary you would like personally.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Provide a short summary of the following document. Your summary should be 3-5 sentences long.\"\n",
    "\n",
    "# add all pages except the last two to the prompt\n",
    "for page in documents[:-2]:\n",
    "    prompt += page.page_content + \"\\n\\n\"\n",
    "\n",
    "print(llm.get_num_tokens(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the document with our summarization prompt\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarize long pdf document in chunks (\"map_reduce\" method)\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <b>Handling large documents</b>\n",
    "  <p>With the wikipedia article on natural language processsing the token limit of our available models is exceeded (even when dropping the references), so we have to find another way to deal with this document. A very efficient way is to split the document into chunks (smaller parts) and generate a lot of summaries of these chunks in parallel (map step). And then afterwards summarize all the generated summaries again (reduce step) to get a final summary. This method is called map reduce.</p>\n",
    "  <p>The map and reduce concept is not exclusive to summarization and can also be applied to other tasks like translation, question answering, etc.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static/map_reduce.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import predefined chain for summarization and text splitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the longer document on NLP and get the number of tokens\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"static/natural_language_processing.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "overall_tokens = 0\n",
    "for page in documents[:-4]:\n",
    "    n_tokens = llm.get_num_tokens(page.page_content)\n",
    "    overall_tokens += n_tokens\n",
    "    \n",
    "print(f\"Overall number of tokens: {overall_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a predefined summarize chain and additionally we need a text splitter to split up our document into chunks. Let's first split the text into chunks of 2000 token (a token is roughle 4 characters so we need to split at 8000 characters) with some overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=500)\n",
    "\n",
    "# put relevant pages into one string\n",
    "article = \"\"\n",
    "for page in documents[:-4]:\n",
    "    article += page.page_content + \"\\n\\n\"\n",
    "\n",
    "# split into chunks with the defined text splitter\n",
    "chunks = text_splitter.create_documents([article])\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(\"Number of tokens in each chunk:\")\n",
    "for chunk in chunks:\n",
    "    print(llm.get_num_tokens(chunk.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\") #, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our chunks and the map_reduce summarization chain we can generate the full summary by inputting the list of chunks into the chain. Setting verbose to True will give the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Documentation: https://python.langchain.com/docs/get_started/introduction\n",
    "- Really comprehensive tutorials: https://github.com/gkamradt/langchain-tutorials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
